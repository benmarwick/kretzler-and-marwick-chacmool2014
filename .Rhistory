top_of_page <- paste0(base_url, relative_urls[i]) %>%
html() %>%
html_nodes('span')
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
print(paste(i, relative_urls[i], sep = " ")) # interactive use only
}
base_url <- "http://www.rdocumentation.org"
github_package_maintainer <- vector("list", length(relative_urls))
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>%
html() %>%
html_nodes('span')
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
print(paste(i, relative_urls[i], sep = " ")) # interactive use only
,
); if(class(result) == "try-error") next;
}
# now get the maintainer for each github package
base_url <- "http://www.rdocumentation.org"
github_package_maintainer <- vector("list", length(relative_urls))
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>%
html() %>%
html_nodes('span');
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
print(paste(i, relative_urls[i], sep = " ")) # interactive use only
,
); if(class(result) == "try-error") next;
}
base_url <- "http://www.rdocumentation.org"
github_package_maintainer <- vector("list", length(relative_urls))
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>%
html() %>%
html_nodes('span');
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
print(paste(i, relative_urls[i], sep = " ")) # interactive use only
); if(class(result) == "try-error") next;
}
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>%
html() %>%
html_nodes('span');
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
print(paste(i, relative_urls[i], sep = " ")) # interactive use only
); if(class(result) == "try-error") next;
}
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>% html() %>% html_nodes('span')
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
print(paste(i, relative_urls[i], sep = " ")) # interactive use only
); if(class(result) == "try-error") next;
}
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>% html() %>% html_nodes('span');
github_package_maintainer[[i]] <- html_text(top_of_page[[8]]);
print(paste(i, relative_urls[i], sep = " ")); # interactive use only
); if(class(result) == "try-error") next;
}
for(i in seq(length(relative_urls))){
# handle errors
result <- try(
top_of_page <- paste0(base_url, relative_urls[i]) %>% html() %>% html_nodes('span');
github_package_maintainer[[i]] <- html_text(top_of_page[[8]]);
print(paste(i, relative_urls[i], sep = " ")); # interactive use only
); if(class(result) == "try-error") next;
}
for(i in seq(length(relative_urls))){
# handle errors
top_of_page <- paste0(base_url, relative_urls[i]) %>% html() %>% html_nodes('span')
result <- try(github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
); if(class(result) == "try-error") next;
print(paste(i, relative_urls[i], sep = " ")); # interactive use only
}
base_url <- "http://www.rdocumentation.org"
github_package_maintainer <- vector("list", length(relative_urls))
for(i in seq(length(relative_urls))){
top_of_page <- paste0(base_url, relative_urls[i]) %>%
html() %>%
html_nodes('span')
# handle errors
result <- try(
github_package_maintainer[[i]] <- html_text(top_of_page[[8]])
); if(class(result) == "try-error") next;
print(paste(i, relative_urls[i], sep = " ")); # interactive use only
}
github_package_maintainer <- unlist(github_package_maintainer)
biocon_package_maintainer
github_package_maintainer
clean_up_github <- function(x){
# get rid of punctuation
x1 <- gsub("[[:punct:]]", " ", x)
# remove leading space before first name
x2 <- str_trim(x1 , side="left")
# get first name only
x3 <- unlist(lapply(x2, first.word))
# gender function only takes lower case
x4 <- tolower(x3)
return(x4)
}
clean_up_github(github_package_maintainer)
clean_up(github_package_maintainer)
github_package_maintainer_first <- clean_up(github_package_maintainer)
github_package_maintainer_with_nas <- gender(github_package_maintainer_first)
github_package_maintainer_gender
github_package_maintainer_with_nas <- unlist(lapply(github_package_maintainer_with_nas, function(i) i$gender))
idx <- !is.na(github_package_maintainer_with_nas)
github_package_maintainer_gender <- github_package_maintainer_with_nas[idx]
github_package_maintainer_gender
table(github_package_maintainer_gender)
github_counts <- data.frame(female = github_package_maintainer_gender == "female" ,
male = github_package_maintainer_gender == "male")
github_counts_l <- melt(github_counts + 0)
github_counts_l
ggplot(github_counts_l, aes(variable, value)) +
geom_bar(stat = "identity") +
theme_minimal(base_size = 14) +
ggtitle("CRAN package maintainers by gender") +
ylab("Number of packages") +
xlab("gender")
ggplot(github_counts_l, aes(variable, value)) +
geom_bar(stat = "identity") +
theme_minimal(base_size = 14) +
ggtitle("GitHub package maintainers by gender") +
ylab("Number of packages") +
xlab("gender")
all <- length(github_package_maintainer_gender)
props <- round(data.frame(female_prop = sum(github_package_maintainer_gender == "female")/all,
github_package_maintainer_gender = sum(cran_genders == "male")/all), 2)
props <- round(data.frame(female_prop =
sum(github_package_maintainer_gender == "female")/all,
github_package_maintainer_gender = sum(cran_genders ==
"male")/all), 2)
gituhub_all <- length(github_package_maintainer_gender)
props <- round(data.frame(female_prop =
sum(github_package_maintainer_gender == "female")/gituhub_all,
github_package_maintainer_gender = sum(cran_genders ==
"male")/gituhub_all), 2)
github_all <- length(github_package_maintainer_gender)
github_props <- round(data.frame(female_prop =
sum(github_package_maintainer_gender == "female")/gituhub_all,
github_package_maintainer_gender = sum(cran_genders ==
"male")/gituhub_all), 2)
github_props_l <- melt(github_props)
ggplot(github_props_l, aes(variable, value)) +
geom_bar(stat = "identity") +
theme_minimal(base_size = 14) +
ggtitle("GitHub package maintainers by gender") +
ylab("Proportion of all packages") +
xlab("gender")
github_all
github_all <- length(github_package_maintainer_gender)
github_props <- round(data.frame(
female_prop =   sum(github_package_maintainer_gender == "female")/gituhub_all,
male_prop = sum(github_package_maintainer_gender == "male")/gituhub_all), 2)
github_props_l <- melt(github_props)
ggplot(github_props_l, aes(variable, value)) +
geom_bar(stat = "identity") +
theme_minimal(base_size = 14) +
ggtitle("GitHub package maintainers by gender") +
ylab("Proportion of all packages") +
xlab("gender")
length(github_package_maintainer_gender)
30 * 0.566
2+2
2+2
help("tm")
?tm
library(tm)
install.packages("tm")
x <- scan("
Leeds:        	        	Symplectic + EPrints  (White Rose)
York:           	        	Pure + EPrints  (White Rose)
Sheffield    	        	Symplectic + EPrints  (White Rose)
Keele:                     	Symplectic + intraLibrary
Queen Mary:         	Symplectic + DSpace
Exeter:                     	Symplectic + DSpace
Plymouth:              	Symplectic + DSpace
St Andrews:          	Pure + DSpace
Edinburgh:            	Pure + DSpace
Leicester:               	Symplectic + DSpace
Leeds Met:             	Symplectic + intraLibrary
Cambridge:           	Symplectic + DSpace
Aberdeen:             	Pure + DSpace
Dundee:                	Pure + DSpace
Royal Holloway:   	Pure + Equella
Strathclyde:           	Pure + EPrints
Hertfordshire:        	Pure + DSpace
Heriot-Watts:          	Pure + DSpace
Bournemouth :      	Symplectic + EPrints
Surrey:                    	Symplectic + Eprints
UCL:                        	Symplectic + Eprints
Oxford:                    	Symplectic + Fedora
Cranfield:              	Converis +DSpace
Stirling:                  	Converis + DSpace
Hull:                        	Converis + Fedora
Brighton:                	Converis + EPrints
Glasgow:		Bespoke + EPrints
Glasgow: Caled	Pure + Digital Commons
Lancaster:		Pure + EPrints
Imperial:		Symplectic + DSpace
Brunel:			Symplectic + DSpace
City Uni London:	Symplectic + EPrints
Aston:			Pure + EPrints
Liverpool Schl Trop Med:			Converis + Eprints
The University of Auckland: 		Symplectic + DSpace
Auckland University of Technology:	Symplectic + DSpace
Massey University:			Symplectic + DSpace")
x <- scan(text = "
Leeds:        	        	Symplectic + EPrints  (White Rose)
York:           	        	Pure + EPrints  (White Rose)
Sheffield    	        	Symplectic + EPrints  (White Rose)
Keele:                     	Symplectic + intraLibrary
Queen Mary:         	Symplectic + DSpace
Exeter:                     	Symplectic + DSpace
Plymouth:              	Symplectic + DSpace
St Andrews:          	Pure + DSpace
Edinburgh:            	Pure + DSpace
Leicester:               	Symplectic + DSpace
Leeds Met:             	Symplectic + intraLibrary
Cambridge:           	Symplectic + DSpace
Aberdeen:             	Pure + DSpace
Dundee:                	Pure + DSpace
Royal Holloway:   	Pure + Equella
Strathclyde:           	Pure + EPrints
Hertfordshire:        	Pure + DSpace
Heriot-Watts:          	Pure + DSpace
Bournemouth :      	Symplectic + EPrints
Surrey:                    	Symplectic + Eprints
UCL:                        	Symplectic + Eprints
Oxford:                    	Symplectic + Fedora
Cranfield:              	Converis +DSpace
Stirling:                  	Converis + DSpace
Hull:                        	Converis + Fedora
Brighton:                	Converis + EPrints
Glasgow:		Bespoke + EPrints
Glasgow: Caled	Pure + Digital Commons
Lancaster:		Pure + EPrints
Imperial:		Symplectic + DSpace
Brunel:			Symplectic + DSpace
City Uni London:	Symplectic + EPrints
Aston:			Pure + EPrints
Liverpool Schl Trop Med:			Converis + Eprints
The University of Auckland: 		Symplectic + DSpace
Auckland University of Technology:	Symplectic + DSpace
Massey University:			Symplectic + DSpace")
?scan
x <- scan(what = character(), text = "
Leeds:        	        	Symplectic + EPrints  (White Rose)
York:           	        	Pure + EPrints  (White Rose)
Sheffield    	        	Symplectic + EPrints  (White Rose)
Keele:                     	Symplectic + intraLibrary
Queen Mary:         	Symplectic + DSpace
Exeter:                     	Symplectic + DSpace
Plymouth:              	Symplectic + DSpace
St Andrews:          	Pure + DSpace
Edinburgh:            	Pure + DSpace
Leicester:               	Symplectic + DSpace
Leeds Met:             	Symplectic + intraLibrary
Cambridge:           	Symplectic + DSpace
Aberdeen:             	Pure + DSpace
Dundee:                	Pure + DSpace
Royal Holloway:   	Pure + Equella
Strathclyde:           	Pure + EPrints
Hertfordshire:        	Pure + DSpace
Heriot-Watts:          	Pure + DSpace
Bournemouth :      	Symplectic + EPrints
Surrey:                    	Symplectic + Eprints
UCL:                        	Symplectic + Eprints
Oxford:                    	Symplectic + Fedora
Cranfield:              	Converis +DSpace
Stirling:                  	Converis + DSpace
Hull:                        	Converis + Fedora
Brighton:                	Converis + EPrints
Glasgow:		Bespoke + EPrints
Glasgow: Caled	Pure + Digital Commons
Lancaster:		Pure + EPrints
Imperial:		Symplectic + DSpace
Brunel:			Symplectic + DSpace
City Uni London:	Symplectic + EPrints
Aston:			Pure + EPrints
Liverpool Schl Trop Med:			Converis + Eprints
The University of Auckland: 		Symplectic + DSpace
Auckland University of Technology:	Symplectic + DSpace
Massey University:			Symplectic + DSpace")
x
x[x == "Symplectic"]
sum(x == "Symplectic")
sum(x == "Converis")
sum(x == "Pure")
# How many using each?
sum(x == "Symplectic")
sum(x == "Pure")
sum(x == "Converis")
sum(x == "Bespoke")
sum(x == "EPrints")
sum(x == "DSpace")
sum(x == "Fedora")
sum(x == "Digital Commons")
sum(x == "intraLibrary")
# How many using each repository?
sum(x == "EPrints")
sum(x == "DSpace")
sum(x == "Fedora")
sum(x == "Digital Commons")
sum(x == "intraLibrary")
sum(x == "Equella")
x
sum(x == "Digital")
sum(x == "Symplectic")
sum(x == "Pure")
sum(x == "Converis")
sum(x == "Bespoke")
lapply(x, function(i) i == "Symplectic")
sapply(x, function(i) i == "Symplectic")
x
which(x == "Symplectic")
which(x == "Symplectic"):2
x1 <- which(x == "Symplectic")
x1 <- which(x == "Symplectic")
x2 <- x1 + 3
x2
x2 <- x1 + 2
x2
x[x1]
x[x2]
sum(x == "Symplectic")
sum(x == "Pure")
sum(x == "Converis")
sum(x == "Bespoke")
table(x[x2])
# if with Symplectic....
x1 <- which(x == "Symplectic")
x2 <- x1 + 2
table(x[x2])
max(table(x[x2]))
table(x[x2])
x1 <- which(x == "Pure")
x2 <- x1 + 2
table(x[x2]) # ... then DSpace
sum(x == "DSpace")
sum(x == "EPrints")
sum(x == "Fedora")
sum(x == "Digital")
sum(x == "intraLibrary")
sum(x == "Equella")
setwd("C:/Users/marwick/docker/kretzler-and-marwick-chacmool2014")
test_data <- list.files(pattern = "zip")
test_data
setwd("/data")
test_data <- list.files(pattern = "zip")
test_data
setwd("C:/Users/marwick/docker/kretzler-and-marwick-chacmool2014")
setwd("/data")
getwd()
setwd("C:/Users/marwick/docker/kretzler-and-marwick-chacmool2014")
setwd(paste0(getwd(),"/data")
)
getwd()
test_data <- list.files(pattern = "zip")
unzip(test_data)
unpack1grams <- JSTOR_unpack1grams()
library(JSTORr)
unpack1grams <- JSTOR_unpack1grams()
getwd()
save(unpack1grams, file = "unpack1grams.rdata", compress = "bzip2")
getRversion()
source('~/.active-rstudio-document', echo=TRUE)
setwd("C:/Users/marwick/docker/kretzler-and-marwick-chacmool2014")
source('~/.active-rstudio-document', echo=TRUE)
unpack1grams$bibliodata
str(unpack1grams$bibliodata)
unpack1grams$bibliodata[ ,x]
as.numeric(unpack1grams$bibliodata[ ,year]
)
unpack1grams$bibliodata[ ,'x']
as.numeric(unpack1grams$bibliodata[ ,'year']
)
# total count for each word?
no_gen_articles <- subset(feminism, feminism[,1] >0)
count_gender_articles <- length(no_gen_articles[,1]) # number of articles containing "gender"
no_feminist_articles <- subset(feminism, feminism[,2] >0)
count_feminism_articles <- length(no_feminist_articles[,2]) # number of articles containing "feminism"
no_feminism_articles <- subset(feminism, feminism[,3] >0)
count_feminist_articles <- length(no_feminism_articles[,3]) # number of articles containing "feminist"
# percent of articles containing 'gender' that also contain feminis*
gender_and_fem <- round((count_feminism_articles + count_feminist_articles) / count_gender_articles * 100, 0)
# this number rises to what after 1984?
## first subset the data to 1984 and later...
bibliodata <- data.frame(doi = unpack1grams$bibliodata[ ,'x'],
year = as.numeric(unpack1grams$bibliodata[ ,'year']),
stringsAsFactors = FALSE)
feminism <- data.frame(feminism)
feminism$doi <- rownames(feminism)
feminism_year <- merge(feminism, bibliodata, by =  'doi')
after_1984 <- feminism_year[feminism_year$year %in% 1982:1987, ]
## now compute percentage again...
after_1984_colsums <- data.frame(t(colSums(after_1984 != 0)))
after_1984_gender_and_fem <- round((after_1984_colsums$feminist + after_1984_colsums$feminism) / after_1984_colsums$gender * 100, 0)
JSTOR_2wordcor(unpack1grams,"gender",c("hunt","hunter","gatherer","gather","role","division","labor"), span = 0.5, yearfrom = 1970, yearto = 2007) +
xlab("correlation between 'gender' and 'hunt', etc.") +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
xlab("correlation between 'gender' and 'hunt', etc.")
JSTOR_2words(unpack1grams, "gender", c("feminism", "feminist"), span = 0.48, yearfrom = 1970, yearto = 2007) +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
JSTOR_2words(unpack1grams, "gender", c("feminism", "feminist"), span = 0.48, yearfrom = 1970, yearto = 2007)
plot1 <- JSTOR_2words(unpack1grams, "gender", c("feminism", "feminist"), span = 0.48, yearfrom = 1970, yearto = 2007)
plot1 +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
plot1$plot
plot1$plot +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
?JSTOR_2words
?JSTOR_1words
?JSTOR_1word
plot1$plot +
scale_y_continuous(trans=log2_trans()) +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
ggsave("figure/2words_gender_feminism.png")
ggsave("figure/2words_gender_feminism.svg")
library(rbokeh)
plot1$words_by_year
View(plot1$words_by_year)
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2)
p
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2) %>%
y_axis(log = TRUE)
p
p <- figure() %>%
ly_points(year, log(value), data = plot1$words_by_year,
hover = V2)
p
plot1$words_by_year$value
p <- figure() %>%
ly_points(year, log(value), data = plot1$words_by_year,
hover = V2) %>%
y_axis(log = TRUE)
p
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2) %>%
y_axis(log = TRUE)
p
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2)
p
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2) %>%
y_axis(log2 = TRUE)
p
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2) %>%
y_axis(log2())
p
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2) %>%
y_axis(log2(value))
p
plot1 <- JSTOR_2words(unpack1grams, "gender", c("feminism", "feminist"), span = 0.48, yearfrom = 1970, yearto = 2007)
plot1$plot +
scale_y_continuous(trans=log2_trans()) +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
ggsave("figure/2words_gender_feminism.png")
ggsave("figure/2words_gender_feminism.svg")
p <- figure() %>%
ly_points(year, value, data = plot1$words_by_year,
hover = V2) %>%
y_axis(log2(value))
p
?ggsave
plot1 <- JSTOR_2words(unpack1grams, "gender", c("feminism", "feminist"), span = 0.48, yearfrom = 1970, yearto = 2007)
plot1$plot +
scale_y_continuous(trans=log2_trans()) +
theme(axis.title.x = element_text(size = 16, colour = 'black'),
axis.title.y = element_text(size = 16, colour = 'black'),
axis.text.x  = element_text(angle = 90, vjust = 0.5, size = 16, colour = 'black'))
ggsave("figure/2words_gender_feminism.png", width = 15, units = "cm")
library(babynames)
data("births")
data("babynames")
